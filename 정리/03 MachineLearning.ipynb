{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os name: nt\n",
      "python ver: 3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]\n",
      "numpy ver: 1.23.4\n",
      "pandas ver: 1.5.0\n",
      "matplotlib ver: 3.6.0\n",
      "seaborn ver: 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('os name:', os.name)\n",
    "print('python ver:', sys.version)\n",
    "print('numpy ver:', np.__version__)\n",
    "print('pandas ver:', pd.__version__)\n",
    "print('matplotlib ver:', matplotlib.__version__)\n",
    "print('seaborn ver:', sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='Malgun Gothic') #한글 폰트 설정\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.min_rows', 30)\n",
    "pd.set_option('display.max_seq_item', 500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통된 컬럼 찾기\n",
    "set(df_y.columns)&set(df_x.columns)\n",
    "\n",
    "# x_train, y_train 합치기\n",
    "df = pd.merge(df_x, df_y, on=['D3', 'D4', 'D5'], how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정보 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "data.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Data 균등 분포 확인(분류 분석 시)\n",
    "- 만약 불균등이라면 SMOTE 방식으로 오버샘플링 처리 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 값이 동일한 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 열 이름 파악\n",
    "df.nunique()\n",
    "\n",
    "#2 제거\n",
    "A = df.loc[:,df.nunique()==1].columns\n",
    "df = df.drop(columns=A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 열 별 결측치 비율 별 처리 방안\n",
    "\n",
    "![](2022-10-28-00-12-43.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 파악 : 중간에 계속 해보면서 NaN이 남아있는 행 파악\n",
    "df.isna().sum().sort_values(\"ascending=False\")\n",
    "\n",
    "# 결측치 시각화(결측치가 아닌 값들을 보여줌)\n",
    "!pip install missingno\n",
    "import missingno as msno\n",
    "missingno.bar(ldf, figsize=(10,5), fontsize=12, sort=\"ascending\")\n",
    "\n",
    "# 결측치가 존재하는 컬럼명 확인\n",
    "df = df.loc[:,  df.isna().sum() > 0 ].columns.values\n",
    "\n",
    "# 결측치 제거\n",
    "df.drop(['A'], axis=1) #특정 컬럼 제거\n",
    "df = df.dropna(axis=0, thresh=10) #NaN 값이 10개 이상인 행 삭제\n",
    "\n",
    "# 결측치 치환(연속형)\n",
    "df = df.fillna(value=5, axis=0, method = None) #bfill, ffill도 가능\n",
    "\n",
    "df = df['X2'].fillna(value=df['X2'].mean()) #평균값으로 치환\n",
    "df['X2'].describe() #치환 후 Data 통계량 확인\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0) #0으로 치환\n",
    "A = imputer.fit_transform(df[['Age', 'Pclass']]) #치환이 필요한 컬럼\n",
    "df['Age','Pclass'] = A #원래 컬럼에 대입\n",
    "\n",
    "# 결측치 치환(범주형)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = 'most_frequent') #최빈값으로 치환\n",
    "result = imputer.fit_transform(train[['Embarked', 'Cabin']])\n",
    "train[['Embarked', 'Cabin']] = result\n",
    "\n",
    "# 특정 조건 만족하는 열 제거\n",
    "df=df.drop(columns=df.loc[:,df.var()==0].columns)\n",
    "\n",
    "# 그 외 불필요한 열 삭제(data_no나 ID 같은 것들)\n",
    "df = df.drop(['data_no', 'Id'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상관 관계 분석\n",
    "- 높은 상관관계를 갖는 독립변수를 찾아서 제거 또는 축소(PCA : 주성분 분석)\n",
    "- 열 제거 시 짝이 되는 독립 변수 중 Target과 Corr이 더 작은 독립변수 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분포 및 변수간 관계 분석(오래 걸림)\n",
    "sns.pairplot(df)\n",
    "#sns.pairplot(iris, vars=['sepal_width', 'sepal_length']) #vars를 사용해 특정 변수만 지정 가능\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 모든 Data 간 선형관계 확인\n",
    "df.corr(numeric_only=True).round(3)\n",
    "# 만약 맨 오른쪽에 독립변수만 object이고 나머지는 다 수치형일 경우: df.iloc[:, :-1].corr() \n",
    "\n",
    "sns.heatmap(df.corr(numeric_only=True).round(2), vmin=-1, cmap='RdBu_r', annot=True)\n",
    "\n",
    "# 독립변수와 종속변수 간 선형관계만 따로 확인(이때 상관관계가 너무 큰 컬럼은 제거 위해)\n",
    "B= df.corr(numeric_only=True)['Y']\n",
    "B = B.loc[B.index!='Y']\n",
    "B\n",
    "\n",
    "# 시각화(독립변수와 종속변수 간 선형관계)\n",
    "sns.barplot(x=B.index, y=B.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 컬럼 별로 Corr이 가장 높은 행에 상관관계, 여기서 1이랑 근접한 열 파악\n",
    "for idx in range(len(df.corr())):\n",
    "    s = df.corr().iloc[idx]\n",
    "    print(s.drop(s.index[idx]).max())\n",
    "\n",
    "# 컬럼 별로 Corr이 가장 높은 행에 상관관계, 여기서 -1이랑 근접한 열 파악\n",
    "for idx in range(len(df.corr())):\n",
    "    s = df.corr().iloc[idx]\n",
    "    print(s.drop(s.index[idx]).min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연속형 자료 분석(이상치 확인)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP\n",
    "1) 단일변수 백분위에서 1%단위마다 위치하는 값 표시(변수.quantile(np.arange(0,1,0.01))\n",
    "2) 단일변수 MIN, MAX값 확인\n",
    "3) 단일변수 히스토그램 확인(크게 벗어난 위치 확인)\n",
    "\n",
    "처리방법\n",
    "1) 단순 삭제 : Human Error 또는 오타에 의한 것이라면 행 삭제\n",
    "2) 다른 값으로 대체 : Data 양이 적을 경우 이상체 제거보다 다른 값(평균, 중간값 등)으로 치환\n",
    "ex) 엄청 큰 값이 1,2개 정도면 다음 작은 Max값으로 대체, 0이 나올 수 없는 수치들은 다음 Min값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Boxplot을 통해 이상치가 포함되어 있는 열 이름 파악\n",
    "df.plot.box()\n",
    "\n",
    "#2 Subplot으로 더 자세히 확인\n",
    "idx = df.loc[:, 'Wafer_Site':'X19']\n",
    "row = 5, column = 4\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "for i, v in enumerate(idx):\n",
    "    plt.subplot(row, column, i+1)\n",
    "    sns.boxplot(y=v, data=df)\n",
    "plt.tight_layout()\n",
    "\n",
    "#3 백분위 별 위치하는 값 확인\n",
    "df['X'].quantile(np.arange(0,1,0.01))\n",
    "\n",
    "#4 단일 변수 Min, Max값 확인\n",
    "df.agg(['max','min'])\n",
    "\n",
    "#5 단인 변수 histogram에서 Data 분포 확인 (나중에 StandardScaler 쓸 때 Outlier가 있으면 성능 저하)\n",
    "plt.hist(df['X'], bins=50)\n",
    "\n",
    "#6 IQR을 사용하여 이상치 제거(변수 별로 봤을 때 이상치에 해당하는 값의 개수가 적으면 사용 자제 - 너무 큰 변환이 됨)\n",
    "Q1, Q3 = df['X'].quantile([0.25, 0.75]) # 이상치 제거하고자 하는 열 입력\n",
    "IQR = Q3-Q1\n",
    "lower_f = Q1 - 1.5*IQR\n",
    "upper_f = Q3 + 1.5*IQR\n",
    "outlier = df.loc[(df['X'] < lower_f) | (df['X'] > upper_f), :]\n",
    "outlier.shape  # 해당되는 Row수 확인, 전체 Row 수 대비 많이 안 지워지는지 확인\n",
    "\n",
    "df_wo_outlier = df.drop(outlier.index, axis=0)\n",
    "df_wo_outlier.shape # 행 삭제 후 비교"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 자료 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby 함수를 활용하여 범주형 자료 별 통계 분석\n",
    "df.groupby(by='A')[['B','C']].agg(['sum', 'mean']) \n",
    "df.groupby(by='A')['B'].quantile(0.75) # 'A' 컬럼에 존재하는 각 변수값 별로 'B' 컬럼에 대해 상위 25%\n",
    "\n",
    "# pitovt_table을 활용하여 열 별 관계 파악\n",
    "df.pivot_table(index=['A','B'], columns='D', values=['C', 'D'], aggfunc='mean', fill_value=0)\n",
    "\n",
    "# 위에서 범주형 자료에 관계를 토대로 한 변수에 지나치게 의존적이면 삭제 \n",
    "\n",
    "# Statistically Significant가 나오면 변수로 넣어주자\n",
    "\n",
    "##### 범주형 - 범주형 두개의 변수는 독립일까? 관계가 있을까?\n",
    "##### 카이제곱 검정\n",
    "##### 귀무가설 : 두 변수의 관계는 독립이다\n",
    "##### 대립가설 : 두 변수의 관계는 독립이 아니다\n",
    "##### p ≤ 0.05 일때 두 변수는 독립이 아닌 관계가 있는 것\n",
    "from scipy import stats\n",
    "\n",
    "def statistical_test(mode, df, cat, target):\n",
    "    uniques= df[cat].unique()    \n",
    "    if mode == 't':   # 범주가 1개, 2개 일때 사용 - 범주별 평균의 차이가 유의미한가? (성별에 따른 키 평균)\n",
    "        group = df.groupby(cat)[target]\n",
    "        samples = [group.get_group(i) for i in uniques]\n",
    "        value, p = stats.ttest_ind(*samples)        \n",
    "    elif mode == 'f':   # 범주가 3개 이상일 때 사용 - 범주별 평균의 차이가 유의미한가? (혈액형에 따른 키 평균)\n",
    "        group = df.groupby(cat)[target]\n",
    "        samples = [group.get_group(i) for i in uniques]\n",
    "        value, p = stats.f_oneway(*samples)\n",
    "    elif mode == 'c':   # 두 개 범주가 독립성을 갖는지 아닌지? (가사노동의 종류와 구성원은 독립적? 연관성?)\n",
    "        contingency = pd.crosstab(index=df[cat], columns=df[target])\n",
    "        value, p, df, expected = stats.chi2_contingency(contingency)\n",
    "        \n",
    "    return value, p, 'Statistically Signifcant' if p<=0.05 else 'Statistically Insignifcant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Series name: None\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "10 non-null     int8 \n",
      "dtypes: int8(1)\n",
      "memory usage: 138.0 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " 0    0\n",
       " 1    1\n",
       " 2    2\n",
       " 3    0\n",
       " 4    0\n",
       " 5    1\n",
       " 6    0\n",
       " 7    1\n",
       " 8    2\n",
       " 9    2\n",
       " dtype: int8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유지해야할 범주형 Data가 있다면 아래 방법들로 수치형으로 변환 필요(사전에 결측치 제거 필요)\n",
    "\n",
    "#1 Label Encoding - 명목형 데이터(성별, 혈액형, 국가, 지역, 부서)에 사용 부적합\n",
    "# 이때 숫자로 바꿔버리면 문자처럼 1대1 대응 방식으로 학습하는게 아니라 숫자들의 크기가 생겨서 관계까지 학습해버려서 안 좋은 결과가 나올 수 있음\n",
    "# 그래서 이건 순서가 의미가 있을 때 사용하는게 좋음(계급, 직급, 점수 등등)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['X'] = le.fit_transform(df['X']) # 변환하고자 하는 문자열 컬럼 대입\n",
    "df['X'].value_counts() #제대로 변환 됐는지 확인\n",
    "\n",
    "le.inverse_transform(df['X']) # 나중에 역변환 시 사용\n",
    "\n",
    "#2 One-Hot Encoding - 명목형 데이터와 더 잘 어울림\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "#기타 s.astype('category').cat.codes 사용법 : 눈에 보일때는 문자열이지만 실제 저장된 것은 숫자\n",
    "s = pd.Series(list(\"ABCAABABCC\"))\n",
    "s = s.astype('category').cat.codes\n",
    "s.info(), s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 독립(X)/종속(Y)변수 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X\n",
    "X = df.iloc[:, :-1]\n",
    "X = df.loc[:,df.columns != '종속 변수']\n",
    "\n",
    "# Y\n",
    "Y = df.iloc[:, -1] \n",
    "Y = df.loc[:,'종속 변수']\n",
    "\n",
    "print(X.shape, Y.shape)  # Row 개수가 동일하지 확인 (Row, Col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Polynomial Features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "degree = 3\n",
    "P = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_poly = P.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- test_size = 0.25: 0.0~1.0 테스트 데이터셋 비율\n",
    "- train_size = None: 0.0~1.0 훈련 데이터셋 비율, test_size를 작성하면 작성하지 않아도 자동 산출\n",
    "- random_state = None: 정수 값, 난수 발생의 시드(seed) 값\n",
    "- stratify: y의 지정한 데이터 비율을 유지(층화 추출), y가 범주형일 때 사용함!!!!! 연속형일 때는 쓰지 말자\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scaler 미사용 시\n",
    "A = train_test_split(X, Y, random_state=0, test_size=0.25, stratify=y)\n",
    "\n",
    "# Scaler 사용 시 X_scaled 확인 필요\n",
    "A = train_test_split(X_scaled, Y, random_state=0, test_size=0.25, stratify=y)  \n",
    "\n",
    "# PolynomialFeatures 사용 시 X_scaled 확인 필요\n",
    "A = train_test_split(X_poly, Y, random_state=0, test_size=0.25) \n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = A\n",
    "\n",
    "[x.shape for x in [x_train, x_test, y_train, y_test]]  #데이터 분할된 비율이 제대로 됐는지 확인 목적\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베스트 알고리즘 출력 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Algorithm = {'Algorithm': 'name', 'TrainScore': 0, 'TestScore': 0}\n",
    "Name = []\n",
    "TrainScore = [] #각각의 Score를 알고리즘 별로 수집해놓기\n",
    "TestScore = []\n",
    "\n",
    "def BestAlgorithm(name, trainScore, testScore):\n",
    "    print()\n",
    "    print(\"현재까지 Best Algorithm\")\n",
    "    if Best_Algorithm['TestScore'] < testScore:\n",
    "        Best_Algorithm['Algorithm'] = name\n",
    "        Best_Algorithm['TrainScore'] = trainScore\n",
    "        Best_Algorithm['TestScore'] = testScore\n",
    "    \n",
    "    Name.append(name)\n",
    "    TrainScore.append(trainScore)\n",
    "    TestScore.append(testScore)\n",
    "    \n",
    "    return Best_Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 모델링(분류-범주형)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_iter = 100: Maximum number of iterations taken for the solvers to converge. Tolerance값보다 작으면 max_iter 전에 빠져나옴\n",
    "    - Undefitting일 경우 크게, overfitting일 경우 작게 설정\n",
    "- tol = 0.0001: Tolerance for stopping criteria.\n",
    "    - Overfitting일 경우 크게 설정\n",
    "- C =1: Inverse of regularization strength; must be a positive float, 규제 강도인 alpha와 반대 개념\n",
    "    - Overfitting일 경우 작게 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_LR = LogisticRegression(penalty='l2', C=1.0, tol=0.0001, random_state=None, max_iter=100).fit(x_train,y_train)\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_gini = DecisionTreeClassifier(criterion='gini', random_state=0).fit(x_train, y_train)\n",
    "tree_ent = DecisionTreeClassifier(criterion='entropy', random_state=0).fit(x_train, y_train)\n",
    "  # criterion : 'gini'(default), 'entropy'\n",
    "  # max_depth = None, 트리의 최대 깊이\n",
    "  # min_sample_split = 2, 노드 내에서 분할이 필요한 최소의 샘플 수\n",
    "  # max_features = None, 최적의 분할을 찾기 위해 고려할 Feature의 수\n",
    "  # max_leaf_nodes=None : 최대 말단 노드 개수\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RFR = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2).fit(x_train, y_train)\n",
    "\n",
    "# Light GBM\n",
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(n_estimators=1000, max_depth=3, num_leaves=31, min_data_in_leaf=20).fit(x_train, y_train)  \n",
    "#과적합시 max_depth, min_data_in_leaf, num_leaves 줄이기\n",
    "\n",
    "# XGB Classifier\n",
    "from xgboost import XGBClassifier\n",
    "model_xgb = XGBClassifier(n_estimators=100, learning_rate=0.4, max_depth=3, objective ='reg:squarederror').fit(x_train, y_train)\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_GBR = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, max_depth=3).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Voting Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "names = ['knn3', 'knn5', 'lr', 'dt3', 'dt5']\n",
    "estimator = [knn3, knn5, lr, dt3, dt5]\n",
    "estimators = list(zip(names,estimator))\n",
    "\n",
    "hard = VotingClassifier(estimators, voting='hard') #hard\n",
    "soft = VotingClassifier(estimators, voting='soft') #soft\n",
    "\n",
    "# KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = range(1, 11)\n",
    "train_score = []\n",
    "test_score = []\n",
    "for k in k_range:\n",
    "    model = KNeighborsClassifier(n_neighbors=k).fit(x_train, y_train)\n",
    "    train_score.append(model.score(x_train, y_train))\n",
    "    test_score.append(model.score(x_test, y_test))\n",
    "print(train_score)\n",
    "print(test_score) \n",
    "\n",
    "# kNN 시각화\n",
    "plt.plot(k_range, train_score, 'ro-', label='Train Accuracy')\n",
    "plt.plot(k_range, test_score, 'bo--', label='Test Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.title('Find Best K-value')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 모델링(회귀-연속형)\n",
    "- alpha(규제 강도): Overfitting 발생 시 모델을 단순화(=규제) 시키기 위한 정도, alpha가 너무 크면 과소적합, 너무 작으면 과대적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression\n",
    "from sklearn.linear_model import LinearRegression  # y1 = a*x1 + b\n",
    "model_LR = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "# Lasso\n",
    "from sklearn.linear_model import Lasso  # L1, 가중치의 절댓값의 합이 최소가 되도록 설정, alpha가 커질수록 사용되는 X 종류가 줄어듬, 사전에 Scaling 필요\n",
    "alpha = 1 \n",
    "model_lasso = Lasso(alpha=alpha).fit(x_train, y_train)\n",
    "\n",
    "# Ridge\n",
    "from sklearn.linear_model import Ridge  # L2, 가중치의 제곱합이 최소가 되도록 설정, 특정 가중치로 쏠리는 형상 방지, 사전에 Scaling 필요\n",
    "alpha = 1 \n",
    "model_ridge = Ridge(alpha=alpha).fit(x_train, y_train)\n",
    "\n",
    "# DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_DTR = DecisionTreeRegressor(max_depth = None, min_samples_split = 2).fit(x_train, y_train)\n",
    "\n",
    "# RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor(n_estimators=100, max_depth=None, min_samples_split=2).fit(x_train, y_train)\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model_GBR = GradientBoostingRegressor(learning_rate=0.1, n_estimators=100, max_depth=3).fit(x_train, y_train)\n",
    "\n",
    "# XGB Regressor\n",
    "from xgboost import XGBRegressor\n",
    "model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.4, max_depth=3, objective ='reg:squarederror').fit(x_train, y_train)\n",
    "\n",
    "# LightGBMRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(n_estimators=1000, max_depth=3, num_leaves=31, min_data_in_leaf=20).fit(x_train, y_train)  \n",
    "#과적합시 max_depth, min_data_in_leaf, num_leaves 줄이기\n",
    "\n",
    "# KNeighborRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "k_range = range(1, 11)\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "Max_test = 0 \n",
    "\n",
    "for k in k_range:\n",
    "    model_knn = KNeighborsRegressor(n_neighbors=k).fit(x_train_k, y_train_k)\n",
    "    trainScore_k = model_knn.score(x_train_k, y_train_k)\n",
    "    testScore_k = model_knn.score(x_test_k, y_test_k)\n",
    "    \n",
    "    if testScore_k > Max_test:\n",
    "        good_train = trainScore_k\n",
    "        good_test = testScore_k\n",
    "        good_k = k\n",
    "        \n",
    "    train_score_knn.append(trainScore_k)\n",
    "    test_score_knn.append(testScore_k)\n",
    "\n",
    "print(f'trainScore : {good_train}')\n",
    "print(f'testScore : {good_test}')\n",
    "\n",
    "# kNN 시각화\n",
    "plt.plot(k_range, train_score, 'ro-', label='Train Accuracy')\n",
    "plt.plot(k_range, test_score, 'bo--', label='Test Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.title('Find Best K-value')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 객체 생성\n",
    "model_xgb = XGBClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# 후보 파라미터 선정\n",
    "params = {'max_depth':[5,7], 'min_child_weight':[1,3], 'colsample_bytree':[0.5,0.75]}\n",
    "\n",
    "# gridsearchcv 객체 정보 입력(어떤 모델, 파라미터 후보, 교차검증 몇 번) 및 튜닝 시작\n",
    "gs_xgb = GridSearchCV(model_xgb, param_grid=params, cv=3).fit(x_train, y_train)\n",
    "\n",
    "#튜닝된 파라미터 출력\n",
    "print(gs_xgb.best_params_)\n",
    "\n",
    "#최고 점수 출력\n",
    "print(gs_xgb.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비선형 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train score : {model.score(x_train, y_train):.3f}') \n",
    "print(f'test score  : {model.score(x_test, y_test):.3f}')\n",
    "\n",
    "\n",
    "# 함수용\n",
    "trainScore = round(model.score(x_train, y_train),3)\n",
    "testScore = round(model.score(x_test, y_test),3)\n",
    "print('train_score:', trainScore_LR, 'test_score:', testScore_LR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실제값\n",
    "y_test\n",
    "\n",
    "#예측값\n",
    "model.predict(x_test)\n",
    "\n",
    "# 처음 5개만 Test 하고 싶을 때\n",
    "y_test.iloc[:5].to_numpy() #실제값(0~4번째 컬럼)\n",
    "model.predict(x_test[:5]) #에측값\n",
    "\n",
    "# 분류 모델일 경우, 범주 별 예측 확률을 출력해주며 가장 높은 확률을 가진 것이 모델의 예측값으로 출력됨\n",
    "model.predict_proba(x_test)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(Name, TrainScore, label='TrainScore')\n",
    "plt.plot(Name, TestScore, label='TestScore')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.5,1.05)\n",
    "plt.grid()\n",
    "plt.title('Find Best Algorithm')\n",
    "plt.legend(loc='lower right',fontsize='x-large')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def print_lr_errors(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)  # = mse**0.5\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(f'MAE:{mae:.3f}, MSE:{mse:.3f}, RMSE:{rmse:.3f}, R2:{r2:.3f}')\n",
    "\n",
    "\n",
    "print_lr_errors(model, x_train, y_train)\n",
    "print_lr_errors(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#평가 지표\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def metrics(y_test,pred):\n",
    "    accuracy = accuracy_score(y_test,pred) #전체에서 맞춘 것의 비율\n",
    "    precision = precision_score(y_test,pred) #예측한 것 중에 맞춘 것\n",
    "    recall = recall_score(y_test,pred) # 실제인 것 중에 맞춘 것\n",
    "    f1 = f1_score(y_test,pred) # precision과 recall의 조화 평균\n",
    "    roc_score = roc_auc_score(y_test,pred,average='macro')\n",
    "    print('정확도 : {0:.2f}, 정밀도 : {1:.2f}, 재현율 : {2:.2f}'.format(accuracy,precision,recall))\n",
    "    print('f1-score : {0:.2f}, auc : {1:.2f}'.format(f1,roc_score,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_true = np.array([0, 1, 0, 0])   # 0 : 3개, 1 : 1개, 불균형한 데이터인 경우 \n",
    "y_pred = np.array([0, 1, 1, 0])\n",
    "cm = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "print(cm)\n",
    "# 전체에서 맞춘것의 비율 : 3/4\n",
    "print('accuracy  : %.2f' % accuracy_score(y_true, y_pred))\n",
    "# positive(1) 로 예측한 것 중에 맞춘 것 : 1/2\n",
    "print('precision : %.2f' % precision_score(y_true, y_pred))\n",
    "# positive(1) 가 실제인 것 중에 맞춘 것 : 1/1\n",
    "print('recall    : %.2f' % recall_score(y_true, y_pred))\n",
    "# f1 : precision, recall 의 조화 평균\n",
    "print('f1        : %.2f' % f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve 그래프에 필요한 데이터 준비\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "FP, TP, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(FP, TP)  \n",
    "\n",
    "#roc_auc = roc_auc_score(y_test, y_pred_proba)  # 동일 방법\n",
    "print('AUC : %.3f' % (roc_auc))\n",
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_train_pred = model.predict(x_train)\n",
    "A = classification_report(y_train, y_train_pred, target_names=[\"Fail\", \"Pass\"])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=10)\n",
    "\n",
    "#모델링\n",
    "def modeling(model,x_train,x_test,y_train,y_test):\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    metrics(y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
