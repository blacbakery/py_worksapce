{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os name: nt\n",
      "python ver: 3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]\n",
      "numpy ver: 1.23.4\n",
      "pandas ver: 1.5.0\n",
      "matplotlib ver: 3.6.0\n",
      "seaborn ver: 0.12.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('os name:', os.name)\n",
    "print('python ver:', sys.version)\n",
    "print('numpy ver:', np.__version__)\n",
    "print('pandas ver:', pd.__version__)\n",
    "print('matplotlib ver:', matplotlib.__version__)\n",
    "print('seaborn ver:', sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 균등 분포 확인(특히 분류 분석 시)\n",
    "value_counts(normalize=True)\n",
    "\n",
    "# Correlation 확인\n",
    "df.corr(numeric_only=True).round(3)\n",
    "df.iloc[:, :-1].corr()  # 가장 오른쪽에 있는 Target값의 dtype이 object인 경우 제외시키기 위해\n",
    "\n",
    "sns.heatmap(df.corr(numeric_only=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]\n",
    "print(X.shape, Y.shape)  # Row 개수가 동일하지 확인 (Row, Col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "degree = 3\n",
    "P = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_poly = P.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "- test_size = 0.25: 0.0~1.0 테스트 데이터셋 비율\n",
    "- train_size = None: 0.0~1.0 훈련 데이터셋 비율, test_size를 작성하면 작성하지 않아도 자동 산출\n",
    "- random_state = None: 정수 값, 난수 발생의 시드(seed) 값\n",
    "- stratify: y의 지정한 데이터 비율을 유지(층화추출), y가 범주형일 때 사용함\n",
    "\n",
    "A = train_test_split(X, Y, random_state=0, test_size=0.25, stratify=y)  # Scaler 미사용 시\n",
    "A = train_test_split(X_scaled, Y, random_state=0, test_size=0.25, stratify=y)  # Scaler 사용 시 X_scaled 확인 필요\n",
    "A = train_test_split(X_poly, Y, random_state=0, test_size=0.25)  # PolynomialFeatures 사용 시 X_scaled 확인 필요\n",
    "x_train, x_test, y_train, y_test = A\n",
    "[x.shape for x in [x_train, x_test, y_train, y_test]]  #데이터 분할된 비율이 제대로 됐는지 확인 목적\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 모델링(분류-범주형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- max_iter = 100: Maximum number of iterations taken for the solvers to converge. Tolerance값보다 작으면 max_iter 전에 빠져나옴\n",
    "- Undefitting일 경우 크게, overfitting일 경우 작게 설정\n",
    "- tol = 0.0001: Tolerance for stopping criteria.\n",
    "- Overfitting일 경우 크게 설정\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', C=1.0, tol=0.0001, random_state=None, max_iter=100)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 모델링(회귀-연속형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha(규제 강도): Overfitting 발생 시 모델을 단순화(=규제) 시키기 위한 정도, alpha가 너무 크면 과소적합, 너무 작으면 과대적합\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  # y1 = a*x1 + b\n",
    "\n",
    "from sklearn.linear_model import Lasso  # L1\n",
    "\n",
    "from sklearn.linear_model import Ridge  # L2\n",
    "alpha = 1 \n",
    "model = Ridge(alpha=alpha).fit(x_train, y_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비선형 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실제값\n",
    "y_test\n",
    "\n",
    "#예측값\n",
    "model.predict(x_test)\n",
    "\n",
    "# 처음 5개만 Test 하고 싶을 때\n",
    "y_test.iloc[:5].to_numpy() #실제값\n",
    "model.predict(x_test[:5]) #에측값\n",
    "\n",
    "# 분류 모델일 경우, 범주 별 예측 확률\n",
    "model.predict_proba(x_test)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def print_lr_errors(model, X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)  # = mse**0.5\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(f'MAE:{mae:.3f}, MSE:{mse:.3f}, RMSE:{rmse:.3f}, R2:{r2:.3f}')\n",
    "\n",
    "\n",
    "print_lr_errors(model, x_train, y_train)\n",
    "print_lr_errors(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 범주형 - 범주형 두개의 변수는 독립일까? 관계가 있을까?\n",
    "##### 카이제곱 검정\n",
    "##### 귀무가설 : 두 변수의 관계는 독립이다\n",
    "##### 대립가설 : 두 변수의 관계는 독립이 아니다\n",
    "##### p ≤ 0.05 일때 두 변수는 독립이 아닌 관계가 있는 것\n",
    "from scipy import stats\n",
    "\n",
    "def statistical_test(mode, df, cat, target):\n",
    "    uniques= df[cat].unique()    \n",
    "    if mode == 't':   # 범주가 1개, 2개 일때 사용 - 범주별 평균의 차이가 유의미한가? (성별에 따른 키 평균)\n",
    "        group = df.groupby(cat)[target]\n",
    "        samples = [group.get_group(i) for i in uniques]\n",
    "        value, p = stats.ttest_ind(*samples)        \n",
    "    elif mode == 'f':   # 범주가 3개 이상일 때 사용 - 범주별 평균의 차이가 유의미한가? (혈액형에 따른 키 평균)\n",
    "        group = df.groupby(cat)[target]\n",
    "        samples = [group.get_group(i) for i in uniques]\n",
    "        value, p = stats.f_oneway(*samples)\n",
    "    elif mode == 'c':   # 두 개 범주가 독립성을 갖는지 아닌지? (가사노동의 종류와 구성원은 독립적? 연관성?)\n",
    "        contingency = pd.crosstab(index=df[cat], columns=df[target])\n",
    "        value, p, df, expected = stats.chi2_contingency(contingency)\n",
    "        \n",
    "    return value, p, 'Statistically Signifcant' if p<=0.05 else 'Statistically Insignifcant'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
